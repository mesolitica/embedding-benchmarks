{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e49a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/mesolitica/malaysian-ultrachat/resolve/main/ultrachat-lom-agc.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f61286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 15 10:39:23 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              63W / 300W |  53652MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a13b4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028f53accdb445759296f7be69ade7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 22 files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing colbert_linear and sparse_linear---------\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "model = BGEM3FlagModel('BAAI/bge-m3',  use_fp16=True, device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85e25f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47e05672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8034, 8034)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts, questions = [], []\n",
    "\n",
    "with open('ultrachat-lom-agc.jsonl') as fopen:\n",
    "    for l in fopen:\n",
    "        l = json.loads(l)\n",
    "        if l[1]['content_ms']:\n",
    "            c = l[0]['content'].strip()\n",
    "            q = l[1]['content_ms'].strip()\n",
    "            if not len(c) or not len(q):\n",
    "                continue\n",
    "            contexts.append(c)\n",
    "            questions.append(q)\n",
    "            \n",
    "len(contexts), len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aab749ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encoding: 100%|██████████| 670/670 [01:45<00:00,  6.37it/s]\n"
     ]
    }
   ],
   "source": [
    "contexts_v = model.encode(contexts, \n",
    "                            batch_size=12, \n",
    "                            max_length=8192,\n",
    "                            )['dense_vecs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b7f152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encoding: 100%|██████████| 670/670 [00:28<00:00, 23.71it/s]\n"
     ]
    }
   ],
   "source": [
    "questions_v = model.encode(questions, \n",
    "                            batch_size=12, \n",
    "                            max_length=8192,\n",
    "                            )['dense_vecs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5300b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "392c765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8034/8034 [05:24<00:00, 24.76it/s]\n"
     ]
    }
   ],
   "source": [
    "tops = {\n",
    "    1: 0,\n",
    "    3: 0,\n",
    "    5: 0,\n",
    "    10: 0,\n",
    "}\n",
    "\n",
    "for i in tqdm(range(len(questions_v))):\n",
    "    argsort = np.argsort(cosine_similarity(questions_v[i].reshape(1, -1), contexts_v)[0])[::-1]\n",
    "    for k in tops.keys():\n",
    "        if i in argsort[:k]:\n",
    "            tops[k] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e858de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.35001244709982576\n",
      "3 0.5311177495643515\n",
      "5 0.6011949215832711\n",
      "10 0.6928055763007219\n"
     ]
    }
   ],
   "source": [
    "for k, v in tops.items():\n",
    "    print(k, v / len(questions_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686906a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
