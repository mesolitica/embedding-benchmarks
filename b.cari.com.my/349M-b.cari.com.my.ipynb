{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9553052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/mesolitica/llama2-embedding/raw/main/test-set/b.cari.com.my-dataset-bge-test.sample.json\n",
    "# !wget https://huggingface.co/datasets/mesolitica/embedding-pair-mining/resolve/main/b.cari.com.my-dataset-bge-test.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "962c97c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 22 05:16:17 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA A100 80G...  On   | 00000001:00:00.0 Off |                    0 |\r\n",
      "| N/A   29C    P0    68W / 300W |  56310MiB / 81920MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA A100 80G...  On   | 00000002:00:00.0 Off |                    0 |\r\n",
      "| N/A   29C    P0    69W / 300W |  44890MiB / 81920MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4176a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0896d7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25492134015e43eb91fcf4856e7e53c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/912 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18097ae043974cce882da65c7403dd0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mistral_contrastive.py:   0%|          | 0.00/2.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mesolitica/mistral-embedding-349m-8k-contrastive:\n",
      "- mistral_contrastive.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41def37539914c2e8ce52dc0a27ef709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/633M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7366ac06758649e2a2f15268b957deb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b87ea96e82d4a4e8f1bbfa718336eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55a4cf0fa9e479bbe30d6d92edc277f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/638 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    'mesolitica/mistral-embedding-349m-8k-contrastive', \n",
    "    use_flash_attention_2 = True,\n",
    "    trust_remote_code = True,\n",
    "    torch_dtype = torch.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained('mesolitica/mistral-embedding-349m-8k-contrastive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31b7d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50537b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('b.cari.com.my-dataset-bge-test.sample.json') as fopen:\n",
    "    rev_data = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5010cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18755/18755 [06:05<00:00, 51.33it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors = {}\n",
    "for k, v in tqdm(rev_data.items()):\n",
    "    try:\n",
    "        padded = tokenizer([k],return_tensors = 'pt', padding = True)\n",
    "        for k_ in padded:\n",
    "            padded[k_] = padded[k_].cuda()\n",
    "\n",
    "        vectors[k] = model.encode(padded).cpu().detach().numpy()[0]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f73c3ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aku yg x reti masak ni nak suruh buat sendiri? Uwaaaa kt mana leh dpt ni..kedai siam xdop kaa'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_string = {no: k for no, (k, v) in enumerate(vectors.items())}\n",
    "string_no = {v: k for k, v in no_string.items()}\n",
    "no_string[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7094d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8279accd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18755, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_vectors = np.array(list(vectors.values()))\n",
    "np_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02fa7630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9541it [02:00, 79.40it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.24953036944270507\n",
      "3 0.4730745147150908\n",
      "5 0.5341264871634315\n",
      "10 0.5970569818409518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tops = {\n",
    "    1: 0,\n",
    "    3: 0,\n",
    "    5: 0,\n",
    "    10: 0,\n",
    "}\n",
    "total = 0\n",
    "with open('b.cari.com.my-dataset-bge-test.jsonl') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        l = json.loads(l)\n",
    "        query = l['query'].strip()\n",
    "        query_no = string_no.get(query)\n",
    "        if query_no is None:\n",
    "            continue\n",
    "        for s in l['pos']:\n",
    "            s = s.strip()\n",
    "            v_s = vectors.get(s)\n",
    "            s_no = string_no.get(s)\n",
    "            if v_s is None:\n",
    "                continue\n",
    "            v_s = np.array(v_s).reshape((1, -1))\n",
    "            argsort = np.argsort(cosine_similarity(v_s, np_vectors)[0])[::-1]\n",
    "            for k in tops.keys():\n",
    "                if s_no in argsort[:k]:\n",
    "                    k_ = k + 1\n",
    "                else:\n",
    "                    k_ = k\n",
    "                if query_no in argsort[:k_]:\n",
    "                    tops[k] += 1\n",
    "            total += 1\n",
    "            \n",
    "for k, v in tops.items():\n",
    "    print(k, v / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17076186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
