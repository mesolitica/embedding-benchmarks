{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd3eacca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/mesolitica/llama2-embedding/raw/main/test-set/b.cari.com.my-dataset-bge-test.sample.json\n",
    "# !wget https://huggingface.co/datasets/mesolitica/embedding-pair-mining/resolve/main/b.cari.com.my-dataset-bge-test.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c35666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 22 05:24:10 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    68W / 300W |  57034MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000002:00:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    69W / 300W |  47686MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49b88ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef5a195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726613d35a6d488c9dc88757f621434f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/954 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd56132edb2417c898d516e1141a0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_contrastive.py:   0%|          | 0.00/2.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mesolitica/llama2-embedding-600m-8k-contrastive:\n",
      "- modeling_contrastive.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd82bb2dcb2e46e999bef8c8f55f2dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272ffb0592be4dc5a0406da957508074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/963 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c8e6bd07ac4decba738aee78ad6f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d133cea1ae8641589d38795e3d32ef23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e93f2dcf5e481582787c09987c80d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    'mesolitica/llama2-embedding-600m-8k-contrastive', \n",
    "    use_flash_attention_2 = True,\n",
    "    trust_remote_code = True,\n",
    "    torch_dtype = torch.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained('mesolitica/llama2-embedding-600m-8k-contrastive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "675ecb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf3c134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('b.cari.com.my-dataset-bge-test.sample.json') as fopen:\n",
    "    rev_data = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d298c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18755/18755 [00:54<00:00, 341.01it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors = {}\n",
    "for k, v in tqdm(rev_data.items()):\n",
    "    try:\n",
    "        padded = tokenizer([k],return_tensors = 'pt', padding = True)\n",
    "        for k_ in padded:\n",
    "            padded[k_] = padded[k_].cuda()\n",
    "\n",
    "        vectors[k] = model.encode(padded).cpu().detach().numpy()[0]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8292c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aku yg x reti masak ni nak suruh buat sendiri? Uwaaaa kt mana leh dpt ni..kedai siam xdop kaa'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_string = {no: k for no, (k, v) in enumerate(vectors.items())}\n",
    "string_no = {v: k for k, v in no_string.items()}\n",
    "no_string[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4b75f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a0aee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18755, 1536)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_vectors = np.array(list(vectors.values()))\n",
    "np_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64f0ca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9541it [03:05, 51.43it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.254539762053851\n",
      "3 0.4815278647463995\n",
      "5 0.5497808390732624\n",
      "10 0.628052598622417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tops = {\n",
    "    1: 0,\n",
    "    3: 0,\n",
    "    5: 0,\n",
    "    10: 0,\n",
    "}\n",
    "total = 0\n",
    "with open('b.cari.com.my-dataset-bge-test.jsonl') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        l = json.loads(l)\n",
    "        query = l['query'].strip()\n",
    "        query_no = string_no.get(query)\n",
    "        if query_no is None:\n",
    "            continue\n",
    "        for s in l['pos']:\n",
    "            s = s.strip()\n",
    "            v_s = vectors.get(s)\n",
    "            s_no = string_no.get(s)\n",
    "            if v_s is None:\n",
    "                continue\n",
    "            v_s = np.array(v_s).reshape((1, -1))\n",
    "            argsort = np.argsort(cosine_similarity(v_s, np_vectors)[0])[::-1]\n",
    "            for k in tops.keys():\n",
    "                if s_no in argsort[:k]:\n",
    "                    k_ = k + 1\n",
    "                else:\n",
    "                    k_ = k\n",
    "                if query_no in argsort[:k_]:\n",
    "                    tops[k] += 1\n",
    "            total += 1\n",
    "            \n",
    "for k, v in tops.items():\n",
    "    print(k, v / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "457ca804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.254539762053851\n",
      "3 0.4815278647463995\n",
      "5 0.5497808390732624\n",
      "10 0.628052598622417\n"
     ]
    }
   ],
   "source": [
    "for k, v in tops.items():\n",
    "    print(k, v / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
