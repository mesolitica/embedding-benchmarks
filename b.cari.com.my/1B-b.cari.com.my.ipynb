{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9553052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/mesolitica/llama2-embedding/raw/main/test-set/b.cari.com.my-dataset-bge-test.sample.json\n",
    "# !wget https://huggingface.co/datasets/mesolitica/embedding-pair-mining/resolve/main/b.cari.com.my-dataset-bge-test.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "962c97c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 22 05:25:09 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA A100 80G...  On   | 00000001:00:00.0 Off |                    0 |\r\n",
      "| N/A   32C    P0   126W / 300W |  59960MiB / 81920MiB |     40%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA A100 80G...  On   | 00000002:00:00.0 Off |                    0 |\r\n",
      "| N/A   28C    P0    68W / 300W |  47686MiB / 81920MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4176a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0896d7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4e14554871422290331ae844daea82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/952 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbff63f1c2fd4013bbc0f37ce2a0b4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_contrastive.py:   0%|          | 0.00/2.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mesolitica/llama2-embedding-1b-8k-contrastive:\n",
      "- modeling_contrastive.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125eff8ecbec4902ae92a525618fad18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820163b88bcf4781891a2bb692db71f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/963 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dee3324735042739a7b253ab5c5ea88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2af499e1bb4497494404a3f01ae1377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d102be48e6ca45c7bf4556dde6af8f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    'mesolitica/llama2-embedding-1b-8k-contrastive', \n",
    "    use_flash_attention_2 = True,\n",
    "    trust_remote_code = True,\n",
    "    torch_dtype = torch.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained('mesolitica/llama2-embedding-1b-8k-contrastive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31b7d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50537b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('b.cari.com.my-dataset-bge-test.sample.json') as fopen:\n",
    "    rev_data = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5010cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18755/18755 [01:37<00:00, 192.24it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors = {}\n",
    "for k, v in tqdm(rev_data.items()):\n",
    "    try:\n",
    "        padded = tokenizer([k],return_tensors = 'pt', padding = True)\n",
    "        for k_ in padded:\n",
    "            padded[k_] = padded[k_].cuda()\n",
    "\n",
    "        vectors[k] = model.encode(padded).cpu().detach().numpy()[0]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b138056f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aku yg x reti masak ni nak suruh buat sendiri? Uwaaaa kt mana leh dpt ni..kedai siam xdop kaa'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_string = {no: k for no, (k, v) in enumerate(vectors.items())}\n",
    "string_no = {v: k for k, v in no_string.items()}\n",
    "no_string[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efaa62e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6112a6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18755, 1536)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_vectors = np.array(list(vectors.values()))\n",
    "np_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a0ab6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9541it [03:23, 46.92it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.29805886036318097\n",
      "3 0.5795241077019412\n",
      "5 0.6581089542892924\n",
      "10 0.7366938008766437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tops = {\n",
    "    1: 0,\n",
    "    3: 0,\n",
    "    5: 0,\n",
    "    10: 0,\n",
    "}\n",
    "total = 0\n",
    "with open('b.cari.com.my-dataset-bge-test.jsonl') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        l = json.loads(l)\n",
    "        query = l['query'].strip()\n",
    "        query_no = string_no.get(query)\n",
    "        if query_no is None:\n",
    "            continue\n",
    "        for s in l['pos']:\n",
    "            s = s.strip()\n",
    "            v_s = vectors.get(s)\n",
    "            s_no = string_no.get(s)\n",
    "            if v_s is None:\n",
    "                continue\n",
    "            v_s = np.array(v_s).reshape((1, -1))\n",
    "            argsort = np.argsort(cosine_similarity(v_s, np_vectors)[0])[::-1]\n",
    "            for k in tops.keys():\n",
    "                if s_no in argsort[:k]:\n",
    "                    k_ = k + 1\n",
    "                else:\n",
    "                    k_ = k\n",
    "                if query_no in argsort[:k_]:\n",
    "                    tops[k] += 1\n",
    "            total += 1\n",
    "            \n",
    "for k, v in tops.items():\n",
    "    print(k, v / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657caeec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
