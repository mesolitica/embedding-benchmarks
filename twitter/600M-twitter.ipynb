{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ffdd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/mesolitica/llama2-embedding/raw/main/test-set/twitter-dataset-bge-test.sample.json\n",
    "# !wget https://huggingface.co/datasets/mesolitica/embedding-pair-mining/resolve/main/twitter-dataset-bge-test.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f61286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 22 06:49:04 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA A100 80G...  On   | 00000001:00:00.0 Off |                    0 |\r\n",
      "| N/A   29C    P0    68W / 300W |  54690MiB / 81920MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA A100 80G...  On   | 00000002:00:00.0 Off |                    0 |\r\n",
      "| N/A   30C    P0    77W / 300W |  47438MiB / 81920MiB |     22%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e25f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9a5c376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    'mesolitica/llama2-embedding-600m-8k-contrastive', \n",
    "    use_flash_attention_2 = True,\n",
    "    trust_remote_code = True,\n",
    "    torch_dtype = torch.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained('mesolitica/llama2-embedding-600m-8k-contrastive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c4c93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47e05672",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('twitter-dataset-bge-test.sample.json') as fopen:\n",
    "    rev_data = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d7ace5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19529/19529 [00:51<00:00, 378.62it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors = {}\n",
    "for k, v in tqdm(rev_data.items()):\n",
    "    try:\n",
    "        padded = tokenizer([k],return_tensors = 'pt', padding = True)\n",
    "        for k_ in padded:\n",
    "            padded[k_] = padded[k_].cuda()\n",
    "\n",
    "        vectors[k] = model.encode(padded).cpu().detach().numpy()[0]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6d66ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'06.05 WIB #Jalan_Layang_MBZ Cikunir - Tambun - Cikarang - Karawang LANCAR; Karawang - Cikarang - Tambun - Cikunir LANCAR.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_string = {no: k for no, (k, v) in enumerate(vectors.items())}\n",
    "string_no = {v: k for k, v in no_string.items()}\n",
    "no_string[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5463fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e318b87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19529, 1536)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_vectors = np.array(list(vectors.values()))\n",
    "np_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8da1277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10462it [04:13, 41.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.1961393388063013\n",
      "3 0.393831817173286\n",
      "5 0.48080763257155534\n",
      "10 0.5977368537830042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tops = {\n",
    "    1: 0,\n",
    "    3: 0,\n",
    "    5: 0,\n",
    "    10: 0,\n",
    "}\n",
    "total = 0\n",
    "with open('twitter-dataset-bge-test.jsonl') as fopen:\n",
    "    for l in tqdm(fopen):\n",
    "        l = json.loads(l)\n",
    "        query = l['query'].strip()\n",
    "        query_no = string_no.get(query)\n",
    "        if query_no is None:\n",
    "            continue\n",
    "        for s in l['pos']:\n",
    "            s = s.strip()\n",
    "            v_s = vectors.get(s)\n",
    "            s_no = string_no.get(s)\n",
    "            if v_s is None:\n",
    "                continue\n",
    "            v_s = np.array(v_s).reshape((1, -1))\n",
    "            argsort = np.argsort(cosine_similarity(v_s, np_vectors)[0])[::-1]\n",
    "            for k in tops.keys():\n",
    "                if s_no in argsort[:k]:\n",
    "                    k_ = k + 1\n",
    "                else:\n",
    "                    k_ = k\n",
    "                if query_no in argsort[:k_]:\n",
    "                    tops[k] += 1\n",
    "            total += 1\n",
    "            \n",
    "for k, v in tops.items():\n",
    "    print(k, v / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71569d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
